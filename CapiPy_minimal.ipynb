{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drou0302/CapiPy/blob/main/CapiPy_minimal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys36wXHl5Dec"
      },
      "source": [
        "\n",
        "\n",
        ">**WELCOME TO minimal CAPIPY COLAB!**\n",
        "---\n",
        "\n",
        "In this colab file, you will find a simplified version of CapiPy with only the most important modules.\n",
        "At the end, there is also the possibilty for you to download your project file to your local computer.\n",
        "All functionalities and files remain the same formatting (see https://github.com/drou0302/CapiPy for more information).\n",
        "\n",
        "The SURFACE ANALYSIS module!\n",
        "\n",
        "To run each of the cells, just press the play button, wait and enjoy!\n",
        "\n",
        "In the different modules, you will be asked to provide full paths to different files or folders.\n",
        "\n",
        "To do so, on the left hand side you have the access to your folder indicated by the üìÅ symbol. By default, all the results are saved in the /content/ folder.\n",
        "\n",
        "To copy a path, select the file or folder and right click, then select 'Copy path' and paste directly that information.\n",
        "\n",
        "A new folder for each of your projects will be created when you run the first cells.\n",
        "\n",
        "**Remember, that CapiPy is thought to be used sequentially, so follow the whole process for optimal results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6UXyYXUzFkku"
      },
      "outputs": [],
      "source": [
        "#@title INSTALLATION - RUN ONLY AT THE START\n",
        "#@markdown Download CONDA for Google collab - save environment for CapiPy.\n",
        "print('Downloading conda...')\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F6NBvvrazJ-T"
      },
      "outputs": [],
      "source": [
        "#@markdown Download all necessary dependencies for CapiPy and install them.\n",
        "print('Installing biopython...')\n",
        "!pip install biopython --root-user-action=ignore\n",
        "!pip install xmltramp2 --root-user-action=ignore\n",
        "!pip install pandas --root-user-action=ignore\n",
        "!pip install py3Dmol --root-user-action=ignore\n",
        "\n",
        "print('Finished! Ready to go!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QtfJiXtUJT0F"
      },
      "outputs": [],
      "source": [
        "#@title Import dependencies and download necessary files - RUN FOR EVERY PROJECT\n",
        "#@markdown Import all necessary dependencies to run the CapiPy modules and download the necessary files for all modules.\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import numpy\n",
        "import time\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import traceback\n",
        "import requests\n",
        "import csv\n",
        "import re\n",
        "import py3Dmol\n",
        "import numpy as np\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "from io import StringIO\n",
        "from Bio.Blast import NCBIWWW\n",
        "from Bio.Blast.Applications import NcbiblastpCommandline\n",
        "from Bio import SeqIO, AlignIO, SearchIO, Align\n",
        "from Bio.PDB import is_aa, PDBList, PDBIO, Superimposer\n",
        "from Bio.PDB.Selection import unfold_entities\n",
        "from Bio.PDB.PDBParser import PDBParser\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from Bio.PDB.Polypeptide import PPBuilder\n",
        "from sys import platform\n",
        "from Bio import BiopythonWarning\n",
        "from Bio.Blast import NCBIXML\n",
        "from Bio.Align import substitution_matrices\n",
        "from Bio.Align.Applications import ClustalwCommandline\n",
        "from Bio import Entrez, Seq, SeqIO, SearchIO\n",
        "clustalw_exe = 'clustalw2'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Create Project Folder.\n",
        "PROJECT_DIR= \"\" #@param {type:\"string\"}\n",
        "#@markdown After creating your folder, upload your pdb file. IT HAS TO BE CLEAN (NO NON-STANDARD RESIDUES!).\n",
        "import os\n",
        "os.chdir('/content/')\n",
        "initial_loc = os.getcwd()\n",
        "\n",
        "if PROJECT_DIR is not \"\":\n",
        "  os.path.isdir(PROJECT_DIR) is False:\n",
        "    os.mkdir(PROJECT_DIR)\n",
        "    os.chdir(PROJECT_DIR)\n",
        "else:\n",
        "  print('Enter your folder name first!')\n"
      ],
      "metadata": {
        "id": "6Vl4xOv4gQTL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "08CiyTawffLz"
      },
      "outputs": [],
      "source": [
        "#@markdown View PDB file. Make sure you have added the pdb file to your project folder.\n",
        "import glob\n",
        "import os\n",
        "\n",
        "initial_loc = os.getcwd()\n",
        "print(initial_loc)\n",
        "print(PROJECT_DIR)\n",
        "if PROJECT_DIR not in initial_loc:\n",
        "  os.chdir(PROJECT_DIR)\n",
        "\n",
        "try:\n",
        "  PDB_FILE = glob.glob('*.pdb')[0]\n",
        "  pdb_exists = True\n",
        "except BaseException:\n",
        "  pdb_exists = False\n",
        "\n",
        "\n",
        "if pdb_exists is True:\n",
        "  found_file = os.path.isfile(PDB_FILE)\n",
        "  os.getcwd()\n",
        "  parser = PDBParser()\n",
        "  model_file_name = 'query'\n",
        "  model_structure = parser.get_structure(model_file_name, PDB_FILE)\n",
        "  model_chain = model_structure.get_chains()\n",
        "  chainid = []\n",
        "  for chains in model_structure.get_chains():\n",
        "      if chains.get_id() not in chainid:\n",
        "          chainid.append(chains.get_id())\n",
        "\n",
        "  import py3Dmol\n",
        "  import os\n",
        "  view = py3Dmol.view()\n",
        "  if os.path.isfile(PDB_FILE) is True:\n",
        "    view.addModel(open(PDB_FILE, 'r').read(),'pdb')\n",
        "    view.setStyle({'model':-1},{'cartoon': {'color':'blue'}})\n",
        "  view.zoomTo()\n",
        "  view.show()\n",
        "\n",
        "else:\n",
        "  print('ERROR - Have you uploaded your PDB file?')\n",
        "\n",
        "os.chdir(initial_loc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W4e-193AjVyN"
      },
      "outputs": [],
      "source": [
        "#@title SURFACE ANALYSIS\n",
        "\n",
        "#@markdown Analysis of the surface of your protein.\n",
        "import random\n",
        "import os\n",
        "import csv\n",
        "from Bio.PDB.Polypeptide import PPBuilder\n",
        "from Bio.PDB import is_aa, PDBList, PDBIO, Superimposer\n",
        "\n",
        "from Bio import BiopythonWarning\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore', BiopythonWarning)\n",
        "\n",
        "import numpy as np\n",
        "from Bio.PDB import HSExposureCB, PDBParser\n",
        "\n",
        "initial_loc = '/content/'\n",
        "os.chdir(initial_loc)\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "\n",
        "file_exist = os.path.isfile(PDB_FILE)\n",
        "\n",
        "if file_exist is True:\n",
        "    print('PDB file found.')\n",
        "else:\n",
        "  print('Cannot find the pdb file. Check again the name!')\n",
        "  quit()\n",
        "\n",
        "# Open the desired pdb file\n",
        "parser = PDBParser(QUIET=True)\n",
        "fullid = \"Q00F\"\n",
        "fullfile = PDB_FILE\n",
        "full_structure = parser.get_structure(fullid, fullfile)\n",
        "mdel = full_structure[0]\n",
        "ppb = PPBuilder()\n",
        "\n",
        "ca_coord = []\n",
        "number_of_chains = 0\n",
        "for chain in mdel.get_list():\n",
        "    number_of_chains += 1\n",
        "for residue in chain.get_list():\n",
        "    if residue.has_id(\"CA\"):\n",
        "        ca = residue[\"CA\"]\n",
        "        ca_coord.append(ca.get_coord())\n",
        "\n",
        "print(\"\\nMeasuring the minimum bounding box...\\n\")\n",
        "\n",
        "ca_coord = np.array(ca_coord)\n",
        "min_x = min(ca_coord[:, 0])\n",
        "min_y = min(ca_coord[:, 1])\n",
        "min_z = min(ca_coord[:, 2])\n",
        "max_x = max(ca_coord[:, 0])\n",
        "max_y = max(ca_coord[:, 1])\n",
        "max_z = max(ca_coord[:, 2])\n",
        "box_dimensions = ([max_x - min_x, max_y - min_y, max_z - min_z])\n",
        "volume = box_dimensions[0] * box_dimensions[1] * box_dimensions[2]\n",
        "print(\"Your protein, formed by \" + str(number_of_chains) + \" chains, has an aproximate dimensions of: \"\n",
        "  + str(box_dimensions[0]) + \" A, \" + str(box_dimensions[1]) + \" A, \" + str(box_dimensions[2]) +\n",
        "  \" A.\\nGiving an aproximate volume of: \" + str(volume) + \" A\\u00b3\\n\")\n",
        "\n",
        "\n",
        "print(\"Calculating the exposure of each residue in the structure...\")\n",
        "RADIUS = 16.0\n",
        "hse_cb = HSExposureCB(mdel, radius=RADIUS)\n",
        "buried = []\n",
        "semiburied = []\n",
        "exposed = []\n",
        "print(\"Sorting the residues depending on their exposure...\")\n",
        "for r in mdel.get_residues():\n",
        "    try:\n",
        "        if is_aa(r) and r.xtra[\"EXP_HSE_B_U\"] >= 35 and r.xtra[\"EXP_HSE_B_D\"] >= 35:\n",
        "          buried.append(r)\n",
        "        elif is_aa(r) and 35 > r.xtra[\"EXP_HSE_B_U\"] >= 25 and 35 > r.xtra[\"EXP_HSE_B_D\"] >= 25:\n",
        "            semiburied.append(r)\n",
        "        elif is_aa(r):\n",
        "            exposed.append(r)\n",
        "    except KeyError:\n",
        "        continue\n",
        "\n",
        "# Calculate the surface in A according to the predicted surface of each amino acid classified as exposed\n",
        "# - 10.1371/journal.pone.0080635\n",
        "aa = [\"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLU\", \"GLN\", \"GLY\", \"HIS\", \"ILE\", \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\",\n",
        "  \"SER\", \"THR\", \"TRP\", \"TYR\", \"VAL\"]\n",
        "\n",
        "aa_ASA = {\"ALA\": 121, \"ARG\": 265, \"ASN\": 187, \"ASP\": 187, \"CYS\": 148, \"GLU\": 214, \"GLN\": 214, \"GLY\": 97,\n",
        "      \"HIS\": 216, \"ILE\": 195, \"LEU\": 191, \"LYS\": 230, \"MET\": 203, \"PHE\": 228, \"PRO\": 154, \"SER\": 143,\n",
        "      \"THR\": 163, \"TRP\": 265, \"TYR\": 255, \"VAL\": 165}\n",
        "\n",
        "totals2 = 0\n",
        "for r in exposed:\n",
        "    totals2 += aa_ASA[r.get_resname()]\n",
        "\n",
        "aa_s2 = {}\n",
        "aa_s2 = aa_s2.fromkeys(aa)\n",
        "aa_n = {}\n",
        "aa_n = aa_n.fromkeys(aa)\n",
        "for exposed_aa in exposed:\n",
        "    try:\n",
        "        aa_s2[exposed_aa.get_resname()] += aa_ASA[exposed_aa.get_resname()]\n",
        "        aa_n[exposed_aa.get_resname()] += 1\n",
        "\n",
        "    except TypeError:\n",
        "       aa_s2[exposed_aa.get_resname()] = aa_ASA[exposed_aa.get_resname()]\n",
        "       aa_n[exposed_aa.get_resname()] = 1\n",
        "\n",
        "\n",
        "aa_s2_perc = {}\n",
        "aa_s2_perc = aa_s2_perc.fromkeys(aa)\n",
        "\n",
        "for aaname in aa:\n",
        "    try:\n",
        "        aa_s2_perc[aaname] = str(\"{:.2f}\".format(((aa_s2[aaname] / totals2) * 100)) + \"%\")\n",
        "    except TypeError:\n",
        "        aa_s2_perc[aaname] = '0%'\n",
        "\n",
        "print(\"Total number of surface residues: \" + str(len(exposed)) + \" out of \" + str(len(exposed) + len(semiburied) + len(buried)))\n",
        "\n",
        "if os.path.exists(\"General_info.txt\"):\n",
        "    check = open(\"General_info.txt\").read()\n",
        "else:\n",
        "    check = \"\"\n",
        "if \"As for\" not in check:\n",
        "    with open(\"General_info.txt\", \"a\") as f1:\n",
        "        print(\"Your protein aproximate dimensions in Angstroms are: \" + str(box_dimensions[0]) + \"A, \" +\n",
        "              str(box_dimensions[1]) + \"A, \" + str(\n",
        "            box_dimensions[2]) + \"A.\\nWhich makes an aproximate volume of: \" +\n",
        "              str(volume) + \" A\\u00b3\\\\n\", file=f1)\n",
        "        print(\"\\nAs for its surface, it measures \" + str(totals2) + \" A\\u00b2\\\\n\", file=f1)\n",
        "        print(\"From which each amino acid contributes to:\", file=f1)\n",
        "        print(\"Aminoacid\\t Surface(%)\\t Total number\", file=f1)\n",
        "        for aa in aa_s2_perc:\n",
        "            print(aa + \"\\t\\t\" + aa_s2_perc[aa] + \"\\t\\t\" + str(aa_n[aa]), file=f1)\n",
        "        print(\"Total number of surface residues: \" + str(len(exposed)), file=f1)\n",
        "\n",
        "\n",
        "aatocheck = [\"LYS\", \"GLU\", \"ASP\", \"HIS\", \"CYS\", \"TYR\", \"ARG\"]  # commonly used for immobilisation#\n",
        "hydrophobic = [\"ILE\", \"LEU\", \"PHE\", \"VAL\", \"TRP\", \"TYR\"]  # arunachalam 2008#\n",
        "charged = []\n",
        "hydroph = []\n",
        "\n",
        "for r in exposed:\n",
        "    name = r.get_resname()\n",
        "    if name in aatocheck:\n",
        "        chainid = r.get_parent().get_id()\n",
        "        resseq = r.get_id()[1]\n",
        "        charged.append(name + \"_\" + str(resseq) + \"_\" + chainid)\n",
        "    elif name in hydrophobic:\n",
        "        chainid = r.get_parent().get_id()\n",
        "        resseq = r.get_id()[1]\n",
        "        hydroph.append(name + \"_\" + str(resseq) + \"_\" + chainid)\n",
        "\n",
        "poslist = []\n",
        "neglist = []\n",
        "hislist = []\n",
        "lyslist = []\n",
        "cyslist = []\n",
        "\n",
        "for item in charged:\n",
        "    if \"LYS\" in item:\n",
        "        poslist.append(item)\n",
        "        lyslist.append(item)\n",
        "    elif \"ASP\" in item or \"GLU\" in item:\n",
        "        neglist.append(item)\n",
        "    elif \"HIS\" in item:\n",
        "        poslist.append(item)\n",
        "        hislist.append(item)\n",
        "    elif \"CYS\" in item:\n",
        "        cyslist.append(item)\n",
        "    elif \"ARG\" in item:\n",
        "        poslist.append(item)\n",
        "\n",
        "def clustering(list1, dic):\n",
        "    # This method checks if the residues in a certain list have their CA at less than 10A.\n",
        "    # If so, this residues will be included in the dictionary as a new cluster\n",
        "    full_structure = parser.get_structure(fullid, fullfile)\n",
        "    i = 0\n",
        "    while i in range(len(list1)):\n",
        "        x1 = list1[i]\n",
        "        for x2 in list1:\n",
        "            if x1 != x2:\n",
        "                dis = mdel[x1.split(\"_\")[2]][int(x1.split(\"_\")[1])][\"CA\"] - \\\n",
        "                      mdel[x2.split(\"_\")[2]][int(x2.split(\"_\")[1])][\"CA\"]\n",
        "                if dis < 10:\n",
        "                    try:\n",
        "                        dic[x1].append(x2)\n",
        "                    except KeyError:\n",
        "                        dic[x1] = [x2]\n",
        "        i += 1\n",
        "\n",
        "def clean(dict1):\n",
        "    # Clean up the dictionaries created with clustering. This avoids repetition of the same cluster as well as\n",
        "    # deletes any cluster formed by less than 3 different aminoacids\n",
        "    dictcopy = dict1.copy()\n",
        "    keys = list(dictcopy.keys())\n",
        "    for key in keys:\n",
        "        if key in dict1[key]:\n",
        "            dict1.pop(key)\n",
        "        elif len(dict1[key]) < 2:\n",
        "            dict1.pop(key)\n",
        "        elif key in str(dict1.values()):\n",
        "            dict1.pop(key)\n",
        "        elif \"\" in dict1[key]:\n",
        "            while \"\" in dict1[key]:\n",
        "                dict1[key].remove(\"\")\n",
        "\n",
        "def writeclusterstocsv(cluster, file):\n",
        "    # Self explanatory. Writes the clusters identified into a csv file.\n",
        "    with open(file, \"a\", newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        if len(cluster) > 1:\n",
        "            for i in cluster:\n",
        "                towrite = [i]\n",
        "                for x in cluster[i]:\n",
        "                    towrite.append(x)\n",
        "                writer.writerow(towrite)\n",
        "            writer.writerow(\"\\n\")\n",
        "\n",
        "def show_clusters(dict):\n",
        "    # Writes the information of teh clusters into a txt file. More \"user friendly\" explanation of the results\n",
        "    f = open(\"Clusters.txt\", \"a\")\n",
        "    if len(dict) > 1:\n",
        "        f.write(list(dict.keys())[0] + \" residues in a cluster (<10A):\\n\")\n",
        "        i = 1\n",
        "        for keys in list(dict.keys())[1:]:\n",
        "            toprint = \"Cluster \" + str(list(dict.keys())[0][0:3].lower()) + str(i) + \":\" + str(keys)\n",
        "            length = len(dict[keys])\n",
        "            x = 0\n",
        "            while x < length:\n",
        "                toprint += \", \" + str(dict[keys][x])\n",
        "                x += 1\n",
        "            toprint += \".\"\n",
        "            print(toprint, file=f)\n",
        "            i += 1\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "def uploadcluster():\n",
        "    # In case the clusters.csv (which is created in the first execution -  is available, file is opened and clusters\n",
        "    # written back into a Python dictionary to continue execution\n",
        "    csv_clusters = csv.reader(open(\"clusters.csv\", \"r\"))\n",
        "    i = 0\n",
        "    keys = [[], [], [], [], [], []]\n",
        "    values = [[], [], [], [], [], []]\n",
        "    with open(\"clusters.csv\", \"r\") as file:\n",
        "        csv_clusters = csv.reader(file)\n",
        "        for row in csv_clusters:\n",
        "            if row[0] == \"\\n\":\n",
        "                i += 1\n",
        "            else:\n",
        "                keys[i].append(row[0])\n",
        "                values[i].append(row[1:])\n",
        "    x = 0\n",
        "    for x in range(len(keys)):\n",
        "        try:\n",
        "            if keys[x][0] == \"Positive\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_pos[keys[0][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Negative\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_neg[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Histidine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_his[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Lysine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_lys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Cysteine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_cys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Hydrophobic\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_hidroph[keys[x][y]] = values[x][y]\n",
        "        except IndexError:\n",
        "            x += 1\n",
        "        x += 1\n",
        "def clusters_pymol(dict):\n",
        "    # Writes the clusters into a pymol command which can be direclty copied into the command line\n",
        "    if len(dict) > 1:\n",
        "        f = open(\"PyMol_clusters.pml\", \"a\")\n",
        "        colours = coloursdic[list(dict.keys())[0]]\n",
        "        i = 0\n",
        "        for keys in dict.keys():\n",
        "            if keys.isalpha() is not True:\n",
        "                toprint = (\"select \" + str(list(dict.keys())[0][0:3].lower()) + str(i) + \", (resi \" + str(\n",
        "                    keys.split(\"_\")[1])) + \" & chain \" + str(dict[keys][1].split(\"_\")[2])\n",
        "                length = len(dict[keys])\n",
        "                x = 0\n",
        "                while x < length:\n",
        "                    toprint += \", resi \" + str(dict[keys][x].split(\"_\")[1]) + \" & chain \" + str(\n",
        "                        dict[keys][x].split(\"_\")[2])\n",
        "                    x += 1\n",
        "                toprint += \")\"\n",
        "                print(toprint, file=f)\n",
        "            i += 1\n",
        "        print(\"color \" + colours + \", \" + str(list(dict.keys())[0][0:3].lower()) + \"*\\n\", file=f)\n",
        "\n",
        "\n",
        "cluster_pos = {\"Positive\": [\"Lys\", \"Arg\", \"His\"]}\n",
        "cluster_neg = {\"Negative\": [\"Asp\", \"Gly\"]}\n",
        "cluster_his = {\"Histidine\": [\"only\", \"histidines\"]}\n",
        "cluster_lys = {\"Lysine\": [\"only\", \"lysines\"]}\n",
        "cluster_cys = {\"Cysteine\": [\"only\", \"cysteines\"]}\n",
        "cluster_hidroph = {\"Hydrophobic\": [\"ILE\", \"LEU\", \"PHE\", \"VAL\", \"TRP\", \"TYR\"]}\n",
        "coloursdic = {\"Positive\": \"Blue\", \"Negative\": \"Red\", \"Histidine\": \"Cyan\", \"Lysine\": \"LightBlue\",\n",
        "              \"Cysteine\": \"Yellow\", \"Hydrophobic\": \"White\"}\n",
        "\n",
        "if os.path.exists(\"clusters.csv\") is True:\n",
        "    print(\"Uploading previously calculated clusters form clusters.csv.\\n\")\n",
        "    uploadcluster()\n",
        "elif os.path.exists(\"clusters.csv\") is False:\n",
        "    print(\"Measuring distances and identifying clusters...\")\n",
        "    clustering(poslist, cluster_pos)\n",
        "    clustering(neglist, cluster_neg)\n",
        "    clustering(hislist, cluster_his)\n",
        "    clustering(lyslist, cluster_lys)\n",
        "    clustering(cyslist, cluster_cys)\n",
        "    clustering(hydroph, cluster_hidroph)\n",
        "    clean(cluster_pos)\n",
        "    clean(cluster_neg)\n",
        "    clean(cluster_his)\n",
        "    clean(cluster_lys)\n",
        "    clean(cluster_cys)\n",
        "    clean(cluster_hidroph)\n",
        "    writeclusterstocsv(cluster_pos, \"clusters.csv\")\n",
        "    writeclusterstocsv(cluster_neg, \"clusters.csv\")\n",
        "    writeclusterstocsv(cluster_his, \"clusters.csv\")\n",
        "    writeclusterstocsv(cluster_lys, \"clusters.csv\")\n",
        "    writeclusterstocsv(cluster_cys, \"clusters.csv\")\n",
        "    writeclusterstocsv(cluster_hidroph, \"clusters.csv\")\n",
        "    show_clusters(cluster_pos)\n",
        "    show_clusters(cluster_neg)\n",
        "    show_clusters(cluster_his)\n",
        "    show_clusters(cluster_lys)\n",
        "    show_clusters(cluster_cys)\n",
        "    show_clusters(cluster_hidroph)\n",
        "    print(\"Clusters can be found in Clusters.txt\")\n",
        "\n",
        "with open(\"PyMol_clusters.pml\", \"w\") as f:\n",
        "    chainid = []\n",
        "    for chains in full_structure.get_chains():\n",
        "        if chains.get_id() not in chainid:\n",
        "            chainid.append(chains.get_id())\n",
        "    if len(chains) > 1:\n",
        "        for chain in chainid:\n",
        "            print(\"set_color shade\" + str(chain) + \"= [1.0, \" + str(random.random()) + \", \" + str(\n",
        "                random.random()) + \"]\", file=f)\n",
        "            print(\"colour shade\" + str(chain) + \", chain \" + str(chain), file=f)\n",
        "clusters_pymol(cluster_pos)\n",
        "clusters_pymol(cluster_neg)\n",
        "clusters_pymol(cluster_his)\n",
        "clusters_pymol(cluster_lys)\n",
        "clusters_pymol(cluster_cys)\n",
        "clusters_pymol(cluster_hidroph)\n",
        "\n",
        "def distointer(cluster, list1):\n",
        "    # Check if the residues in the cluser can interfere with the protein interface\n",
        "    itemslist = []\n",
        "    for kcluster in list(cluster.keys())[1:]:\n",
        "        itemslist.append(kcluster)\n",
        "        for values in cluster[kcluster]:\n",
        "            itemslist.append(values)\n",
        "    for pos1 in itemslist:\n",
        "        try:\n",
        "          for pos2 in interface_res[\"A\"]:\n",
        "              dis = mdel[str(pos1.split(\"_\")[2])][int(pos1.split(\"_\")[1])][\"CA\"] - mdel[\"A\"][pos2][\"CA\"]\n",
        "              if dis != 0 and dis <= 10 and (pos1 not in list1):\n",
        "                list1.append(pos1)\n",
        "        except KeyError:\n",
        "              continue\n",
        "\n",
        "def writecluster(original, d1, list1, file):\n",
        "    # Similar to show_cluster method, it writes the information into a .txt file. In this case, it will add a\n",
        "    # -Warning- if the cluster is close to the specified residues.'''\n",
        "    it = 1\n",
        "    f = open(file, \"a\")\n",
        "    with open(file) as readfile:\n",
        "        if \"Chain\" not in readfile.read():\n",
        "            f.write(\"Searching for clusters in close contact to: \")\n",
        "            if isinstance(original, dict) is True:\n",
        "                for aas in original:\n",
        "                    f.write(\"\\nChain \" + str(aas) + \":\")\n",
        "                    for aas2 in original[aas]:\n",
        "                        f.write(\" - \" + str(aas2))\n",
        "            elif isinstance(original, list):\n",
        "                for aas in original:\n",
        "                    f.write(\" - \" + str(aas))\n",
        "            readfile.close()\n",
        "        else:\n",
        "            readfile.close()\n",
        "    f.write(\"\\n\" + list(d1.keys())[0] + \" residues in a cluster (<10A):\\n\")\n",
        "    inlist1 = []\n",
        "    for k in list(d1.keys())[1:]:\n",
        "        toprint = \"Cluster \" + str(list(d1.keys())[0][0:3].lower()) + str(it) + \":\" + str(k)\n",
        "        length = len(d1[k])\n",
        "        inlist1.append(k)\n",
        "        x = 0\n",
        "        while x < length:\n",
        "            toprint += \", \" + str(d1[k][x])\n",
        "            inlist1.append(d1[k][x])\n",
        "            x += 1\n",
        "        toprint += \".\"\n",
        "        for ex in inlist1:\n",
        "            if ex in list1 and \"\\t -In close proximity to specified residue/s - \" not in toprint:\n",
        "                toprint += \"\\t -In close proximity to specified residue/s - \"\n",
        "        print(toprint, file=f)\n",
        "        it += 1\n",
        "    f.write(\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "# Start first, identifying how many chains does the model have. Maximum of 10 for convenience\n",
        "# (and because most proteins fall into this category).\n",
        "chainres = {\"A\": [], \"B\": [], \"C\": [], \"D\": [], \"E\": [], \"F\": [], \"G\": [], \"H\": [], \"I\": [], \"J\": []}\n",
        "chainids = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n",
        "\n",
        "# number of chains in model\n",
        "number_of_chains = 0\n",
        "for chain in mdel.get_chains():\n",
        "    number_of_chains += 1\n",
        "\n",
        "# Create dictionary with all CA location of a chain\n",
        "for x in range(number_of_chains):\n",
        "    for residues in mdel[chainids[x]]:\n",
        "        if is_aa(residues) is True:\n",
        "            chainres[chainids[x]].append(residues[\"CA\"])\n",
        "\n",
        "# Delete unnecessary keys in the chainres dictionary\n",
        "for a in range(len(chainres.keys())):\n",
        "    if len(chainres[chainids[a]]) == 0:\n",
        "        del chainres[chainids[a]]\n",
        "\n",
        "# calculation of the interface residues. This will assume all chains will have the same interactions as chain A.\n",
        "# This simplification is necessary to get results in a reasonable time.\n",
        "interface_res = {\"A\": []}\n",
        "\n",
        "if number_of_chains > 1:\n",
        "    print(\"Calculating if any of the clusters might affect the quaternary structure of your protein. \\n \"\n",
        "          \"Note: This assumes chain A is in contact with all other subunits and all contacts are identical \"\n",
        "          \"between subunits.\\n\")\n",
        "\n",
        "calculationdone = os.path.exists(\"residues_interface.txt\")\n",
        "\n",
        "print(\"Calculating contacts between chain A and it's neighbours...\")\n",
        "ch_1 = 1\n",
        "# Calculate the distance of all atoms in chain A to all atoms in other chains. If this distance is <10A,\n",
        "# the position will be added as part of the interface.\n",
        "while ch_1 < number_of_chains:\n",
        "    for ca1 in chainres[\"A\"]:\n",
        "        for ca2 in chainres[chainids[ch_1]]:\n",
        "            if ca1.get_parent().get_id()[1] not in interface_res[\"A\"]:\n",
        "                dist = ca1 - ca2\n",
        "                if 0 < dist < 10:\n",
        "                    interface_res[\"A\"].append(ca1.get_parent().get_id()[1])\n",
        "    ch_1 += 1\n",
        "\n",
        "    # Assuming all contacts in the different chains are the same as in chain A,\n",
        "    # copy the residue position to each chain.\n",
        "    count_start = 1\n",
        "    for count_start in range(number_of_chains):\n",
        "        interface_res[chainids[count_start]] = interface_res[\"A\"]\n",
        "        count_start += 1\n",
        "\n",
        "    # Write information to file so it doesn't have to be calculated again.\n",
        "    with open(\"residues_interface.txt\", \"a\") as fileint:\n",
        "        print(interface_res, file=fileint)\n",
        "    print(\"The position of the residues identified as part of the interface can be found in residues_interface.txt\")\n",
        "\n",
        "# Calculate now if any of the identified clusters is at less than 10A to the any of the interface residues.\n",
        "intpos = []\n",
        "intneg = []\n",
        "inthis = []\n",
        "intlys = []\n",
        "intcys = []\n",
        "inthidroph = []\n",
        "\n",
        "distointer(cluster_pos, intpos)\n",
        "writecluster(interface_res, cluster_pos, intpos, \"Interface_contacts.txt\")\n",
        "distointer(cluster_neg, intneg)\n",
        "writecluster(interface_res, cluster_neg, intneg, \"Interface_contacts.txt\")\n",
        "distointer(cluster_his, inthis)\n",
        "writecluster(interface_res, cluster_his, inthis, \"Interface_contacts.txt\")\n",
        "distointer(cluster_lys, intlys)\n",
        "writecluster(interface_res, cluster_lys, intlys, \"Interface_contacts.txt\")\n",
        "distointer(cluster_cys, intcys)\n",
        "writecluster(interface_res, cluster_cys, intcys, \"Interface_contacts.txt\")\n",
        "distointer(cluster_hidroph, inthidroph)\n",
        "writecluster(interface_res, cluster_hidroph, inthidroph, \"Interface_contacts.txt\")\n",
        "print(\"Distance to the multimeric interface successful. Your results can be found in Cluster_interface.txt\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "with open('General_info.txt', 'r') as f1:\n",
        "    with open('Graph_data.txt', 'w') as f2:\n",
        "        write = False\n",
        "        for line in f1:\n",
        "            if 'Aminoacid\t Surface(%)\t Total number' in line:\n",
        "                write = True\n",
        "            elif 'Total number of surface residues' in line:\n",
        "                write = False\n",
        "\n",
        "            if write == True:\n",
        "                f2.write(line)\n",
        "\n",
        "with open('Graph_data.txt', 'r') as fin:\n",
        "    data = fin.read().splitlines(True)\n",
        "with open('Graph_data.txt', 'w') as fout:\n",
        "    fout.writelines(data[1:])\n",
        "\n",
        "surface = pd.read_csv('Graph_data.txt', delimiter='\t\t',)\n",
        "surface.loc[20] = list(surface.columns)\n",
        "surface = surface.set_axis(['Aa', 'Percentage', 'Total number'], axis=1)\n",
        "surface = surface.replace(['%'], [''], regex=True)\n",
        "surface[\"Percentage\"] = pd.to_numeric(surface[\"Percentage\"])\n",
        "values = pd.DataFrame(data = list(surface['Percentage']))\n",
        "values = values.transpose()\n",
        "values = values.set_axis(list(surface['Aa']), axis=1)\n",
        "\n",
        "\n",
        "color_list = ['lightsteelblue', 'azure', 'red', 'yellow','orangered',\n",
        "              'teal', 'lightgrey', 'cyan', 'palegreen', 'seagreen',\n",
        "              'dodgerblue','gold','thistle','lavenderblush','orange',\n",
        "              'moccasin','pink','orchid','honeydew','darkgray']\n",
        "\n",
        "bar = values.plot(kind='barh', stacked=True, xlim=[0,100],\n",
        "                   ylabel = '', xlabel = 'Surface percentage (%)',\n",
        "                   color = color_list, legend=False, edgecolor='black')\n",
        "bar.set_title('Surface analysis', weight=\"bold\")\n",
        "bar.legend(bbox_to_anchor =(0., -0.5, 1., -0.1), loc='lower center',\n",
        "           ncol = 5, fancybox = True)\n",
        "\n",
        "\n",
        "buf = io.BytesIO()\n",
        "bar.figure.savefig(buf, format='png', dpi=300,  bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LeEwshu61iJ-"
      },
      "outputs": [],
      "source": [
        "#@markdown Show 3D structure with the clusters\n",
        "os.chdir('/content/')\n",
        "os.chdir(PROJECT_DIR)\n",
        "PDB_FILE =  glob.glob('*.pdb')[0]\n",
        "FILE_CLUSTERS =  glob.glob('clusters.csv')[0]\n",
        "\n",
        "import py3Dmol\n",
        "import os\n",
        "\n",
        "def uploadcluster(FILE):\n",
        "    # In case the clusters.csv (which is created in the first execution -  is available, file is opened and clusters\n",
        "    # written back into a Python dictionary to continue execution\n",
        "    csv_clusters = csv.reader(open(FILE, \"r\"))\n",
        "    i = 0\n",
        "    cluster_pos, cluster_neg, cluster_his, cluster_lys, cluster_cys, cluster_hidroph = {}, {} ,{} ,{} ,{} ,{}\n",
        "    keys = [[], [], [], [], [], []]\n",
        "    values = [[], [], [], [], [], []]\n",
        "    with open(FILE, \"r\") as file:\n",
        "        csv_clusters = csv.reader(file)\n",
        "        for row in csv_clusters:\n",
        "            if row[0] == \"\\n\":\n",
        "                i += 1\n",
        "            else:\n",
        "                keys[i].append(row[0])\n",
        "                values[i].append(row[1:])\n",
        "\n",
        "    for x in range(len(keys)):\n",
        "        try:\n",
        "            if keys[x][0] == \"Positive\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_pos[keys[0][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Negative\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_neg[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Histidine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_his[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Lysine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_lys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Cysteine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_cys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Hydrophobic\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_hidroph[keys[x][y]] = values[x][y]\n",
        "        except IndexError:\n",
        "            x += 1\n",
        "        x += 1\n",
        "    return cluster_pos, cluster_neg, cluster_his, cluster_lys, cluster_cys, cluster_hidroph\n",
        "\n",
        "\n",
        "def num_cluster(DICT):\n",
        "  list1 = []\n",
        "  for k in list(DICT.keys()):\n",
        "    if '_' in k:\n",
        "      list1.append(k.split('_')[1])\n",
        "  list2 = []\n",
        "  for v_list in list(DICT.values()):\n",
        "      for v in v_list:\n",
        "          if '_' in v:\n",
        "              list2.append(v.split('_')[1])\n",
        "  list3 = list1 + list2\n",
        "  return list3\n",
        "\n",
        "\n",
        "\n",
        "if os.path.exists(FILE_CLUSTERS) is True:\n",
        "    r_cluster_pos, r_cluster_neg, r_cluster_his, r_cluster_lys, r_cluster_cys, r_cluster_hidrop = uploadcluster(FILE_CLUSTERS)\n",
        "    cluster_pos = num_cluster(r_cluster_pos)\n",
        "    cluster_neg = num_cluster(r_cluster_neg)\n",
        "    cluster_his = num_cluster(r_cluster_his)\n",
        "    cluster_lys = num_cluster(r_cluster_lys)\n",
        "    cluster_cys = num_cluster(r_cluster_cys)\n",
        "    cluster_hidrop = num_cluster(r_cluster_hidrop)\n",
        "elif os.path.exists(FILE_CLUSTERS) is False:\n",
        "    print('Cannot find the clutsers.csv file.. make sure you pointed to the correct path!')\n",
        "\n",
        "import py3Dmol\n",
        "view = py3Dmol.view()\n",
        "try:\n",
        "    view.addModel(open(PDB_FILE,'r').read(),'pdb')\n",
        "except FileNotFoundError:\n",
        "    print('There is no pdb file in the Surface folder... and it should be named query.pdb!')\n",
        "\n",
        "view.setStyle({'model':-1},{'cartoon': {'color':'white'}})\n",
        "view.setBackgroundColor('black')\n",
        "view.setStyle({'resi': cluster_pos}, {\"sphere\": {'color': 'blue'}})\n",
        "view.setStyle({'resi': cluster_neg}, {\"sphere\": {'color': 'red'}})\n",
        "view.setStyle({'resi': cluster_his}, {\"sphere\": {'color': 'cyan'}})\n",
        "view.setStyle({'resi': cluster_lys}, {\"sphere\": {'color': 'lightblue'}})\n",
        "view.setStyle({'resi': cluster_cys}, {\"sphere\": {'color': 'yellow'}})\n",
        "view.setStyle({'resi': cluster_hidrop}, {\"sphere\": {'color': 'white'}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "egE10AK8jH3l"
      },
      "outputs": [],
      "source": [
        "#@title OPTIONAL - MODULE 3.1- CLUSTER DISTANCE\n",
        "#@markdown Determine the distance between any user defined residue in your structure and the different clusters.\n",
        "os.chdir('/content/')\n",
        "os.chdir(PROJECT_DIR)\n",
        "PDB_FILE = glob.glob('*.pdb')[0]\n",
        "#@markdown Enter the residues to calculate distance to with the number and the chain and separated by a comma. Ex. 1_A, 200_B\n",
        "RESIDUES =  '50_A' #@param {type:\"string\"}\n",
        "#@markdown Enter the file name to save your results.\n",
        "FILE_NAME =  'disteance_to_AS' #@param {type:\"string\"}\n",
        "\n",
        "import py3Dmol\n",
        "\n",
        "residues = RESIDUES.split(',')\n",
        "\n",
        "# Open the desired pdb file\n",
        "parser = PDBParser()\n",
        "fullid = \"Q00F\"\n",
        "pdbfiles = []\n",
        "fullfile = PDB_FILE\n",
        "full_structure = parser.get_structure(fullid, fullfile)\n",
        "mdel = full_structure[0]\n",
        "ppb = PPBuilder()\n",
        "\n",
        "def uploadcluster(FILE):\n",
        "    # In case the clusters.csv (which is created in the first execution -  is available, file is opened and clusters\n",
        "    # written back into a Python dictionary to continue execution\n",
        "    i = 0\n",
        "    cluster_pos, cluster_neg, cluster_his, cluster_lys, cluster_cys, cluster_hidrop = {}, {} ,{} ,{} ,{} ,{}\n",
        "    keys = [[], [], [], [], [], []]\n",
        "    values = [[], [], [], [], [], []]\n",
        "    with open(FILE, \"r\") as file:\n",
        "        csv_clusters = csv.reader(file)\n",
        "        for row in csv_clusters:\n",
        "            if row[0] == \"\\n\":\n",
        "                i += 1\n",
        "            else:\n",
        "                keys[i].append(row[0])\n",
        "                values[i].append(row[1:])\n",
        "    x = 0\n",
        "    for x in range(len(keys)):\n",
        "        try:\n",
        "            if keys[x][0] == \"Positive\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_pos[keys[0][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Negative\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_neg[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Histidine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_his[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Lysine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_lys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Cysteine\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_cys[keys[x][y]] = values[x][y]\n",
        "            elif keys[x][0] == \"Hydrophobic\":\n",
        "                for y in range(len(keys[x])):\n",
        "                    cluster_hidroph[keys[x][y]] = values[x][y]\n",
        "        except IndexError:\n",
        "            x += 1\n",
        "        x += 1\n",
        "    return cluster_pos, cluster_neg, cluster_his,cluster_lys, cluster_cys, cluster_hidrop\n",
        "def num_cluster(DICT):\n",
        "    list1 = []\n",
        "    for k in list(DICT.keys()):\n",
        "      if '_' in k:\n",
        "        list1.append(k.split('_')[1])\n",
        "    list2 = []\n",
        "    for v_list in list(DICT.values()):\n",
        "        for v in v_list:\n",
        "            if '_' in v:\n",
        "                list2.append(v.split('_')[1])\n",
        "    list3 = list1 + list2\n",
        "    return list3\n",
        "\n",
        "\n",
        "def distonrl(cluster):\n",
        "    # Similarly to the other distance methods, calculates if any residues of the cluster is at less than 10A\n",
        "    # of any of the residues defined by the user\n",
        "    itemslist = []\n",
        "    list1=[]\n",
        "    for k0 in list(cluster.keys())[1:]:\n",
        "        itemslist.append(k0)\n",
        "        for values in cluster[k0]:\n",
        "            itemslist.append(values)\n",
        "    for i1 in itemslist:\n",
        "        for k1 in nrl_dic.keys():\n",
        "            for v0 in nrl_dic[k1]:\n",
        "                dis = mdel[str(i1.split(\"_\")[2])][int(i1.split(\"_\")[1])][\"CA\"] - mdel[str(k1)][int(v0)][\"CA\"]\n",
        "                if dis != 0 and dis < 10 and i1 not in list1:\n",
        "                    list1.append(i1)\n",
        "                elif IndexError:\n",
        "                    continue\n",
        "    return list1\n",
        "\n",
        "def writecluster(original, d1, list1, file):\n",
        "    # Writes the information into a .txt file. In this case, it will add a -Warning- if the cluster is close\n",
        "    # to the specified residues.\n",
        "    if len(d1) > 0:\n",
        "        it = 1\n",
        "        f = open(file, \"a\")\n",
        "        with open(file) as readfile:\n",
        "            if \"Chain\" not in readfile.read():\n",
        "                f.write(\"Searching for clusters in close contact to: \")\n",
        "                if isinstance(original, dict) is True:\n",
        "                    for aas in original:\n",
        "                        f.write(\"\\nChain \" + str(aas) + \":\")\n",
        "                        for aas2 in original[aas]:\n",
        "                            f.write(\" - \" + str(aas2))\n",
        "                elif isinstance(original, list):\n",
        "                    for aas in original:\n",
        "                        f.write(\" - \" + str(aas))\n",
        "                readfile.close()\n",
        "            else:\n",
        "                readfile.close()\n",
        "        f.write(\"\\n\" + list(d1.keys())[0] + \" residues in a cluster (<10A):\\n\")\n",
        "        inlist1 = []\n",
        "        for k in list(d1.keys())[1:]:\n",
        "            toprint = \"Cluster \" + str(list(d1.keys())[0][0:3].lower()) + str(it) + \":\" + str(k)\n",
        "            length = len(d1[k])\n",
        "            inlist1.append(k)\n",
        "            x = 0\n",
        "            while x < length:\n",
        "                toprint += \", \" + str(d1[k][x])\n",
        "                inlist1.append(d1[k][x])\n",
        "                x += 1\n",
        "            toprint += \".\"\n",
        "            for ex in inlist1:\n",
        "                if ex in list1 and \"\\t -In close proximity to specified residue/s - \" not in toprint:\n",
        "                    toprint += \"\\t -In close proximity to specified residue/s - \"\n",
        "            print(toprint, file=f)\n",
        "            it += 1\n",
        "        f.write(\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "\n",
        "def distance_pml(dict, file):\n",
        "    filename= FILE_NAME + '.pml'\n",
        "    # Writes the clusters into a pymol command which can be directly copied into the command line\n",
        "    for key in dict.keys():\n",
        "        writing = 'select res_group ('\n",
        "        j=0\n",
        "        item_n = 0\n",
        "        for aa_n in dict[key]:\n",
        "            length = len(dict[key])\n",
        "            if item_n == 0:\n",
        "                writing += 'resi ' + aa_n + ' & chain ' + key\n",
        "                item_n += 1\n",
        "            else:\n",
        "                writing += ', resi ' + aa_n + ' & chain ' + key\n",
        "                item_n += 1\n",
        "        writing += ')\\n'\n",
        "        writing += 'zoom (res_group)'\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(writing)\n",
        "    return filename\n",
        "\n",
        "\n",
        "# Extract from the pdb file the chain id and the sequence of each chain saved into a dictionary.\n",
        "\n",
        "cluster_pos, cluster_neg, cluster_his,cluster_lys, cluster_cys, cluster_hidrop = uploadcluster(glob.glob('clusters.csv')[0])\n",
        "num_cluster_pos = num_cluster(cluster_pos)\n",
        "num_cluster_neg = num_cluster(cluster_neg)\n",
        "num_cluster_his = num_cluster(cluster_his)\n",
        "num_cluster_lys = num_cluster(cluster_lys)\n",
        "num_cluster_cys = num_cluster(cluster_cys)\n",
        "num_cluster_hidrop = num_cluster(cluster_hidroph)\n",
        "\n",
        "c_ids = {}\n",
        "for chains in mdel:\n",
        "    c_ids[chains.get_id()] = []\n",
        "for chains in c_ids:\n",
        "    c_ids[chains] = [ppb.build_peptides(mdel[chains])[0][0].get_id()[1],\n",
        "                     ppb.build_peptides(mdel[chains])[0][-1].get_id()[1]]\n",
        "\n",
        "# Ask user for the specific residues to check. Check that the specified residues exist in the pdb file.\n",
        "# nrl = new residues list, but I wanted to keep it short.\n",
        "nrl = residues\n",
        "for res in nrl:\n",
        "    if res.split(\"_\")[1] not in c_ids.keys():\n",
        "        print(\"\\nIt seems that your input is part of an unexistent chain.\")\n",
        "        quit()\n",
        "    elif int(res.split(\"_\")[0]) not in range(c_ids[res.split(\"_\")[1]][0], c_ids[res.split(\"_\")[1]][1]):\n",
        "        print(\"\\nIt seems that your input is not part of the pdb file.\")\n",
        "        quit()\n",
        "\n",
        "nrl_dic = {}\n",
        "for posit in nrl:\n",
        "    if posit.split(\"_\")[1] in nrl_dic.keys():\n",
        "        nrl_dic[posit.split(\"_\")[1]].append(posit.split(\"_\")[0])\n",
        "    else:\n",
        "        nrl_dic[posit.split(\"_\")[1]] = [posit.split(\"_\")[0]]\n",
        "\n",
        "perspos = distonrl(cluster_pos)\n",
        "persneg = distonrl(cluster_neg)\n",
        "pershis = distonrl(cluster_his)\n",
        "perslys = distonrl(cluster_lys)\n",
        "perscys = distonrl(cluster_cys)\n",
        "pershidroph = distonrl(cluster_hidroph)\n",
        "\n",
        "spfile = FILE_NAME\n",
        "\n",
        "writecluster(nrl_dic, cluster_pos, perspos, spfile + \".txt\")\n",
        "writecluster(nrl_dic, cluster_neg, persneg, spfile + \".txt\")\n",
        "writecluster(nrl_dic, cluster_his, pershis, spfile + \".txt\")\n",
        "writecluster(nrl_dic, cluster_lys, perslys, spfile + \".txt\")\n",
        "writecluster(nrl_dic, cluster_cys, perscys, spfile + \".txt\")\n",
        "writecluster(nrl_dic, cluster_hidrop, pershidroph, spfile + \".txt\")\n",
        "\n",
        "num_dist_pos = [x.split('_')[1] for x in perspos]\n",
        "num_dist_neg = [x.split('_')[1] for x in persneg]\n",
        "num_dist_his = [x.split('_')[1] for x in pershis]\n",
        "num_dist_lys = [x.split('_')[1] for x in perslys]\n",
        "num_dist_cys = [x.split('_')[1] for x in perscys]\n",
        "num_dist_hidrop = [x.split('_')[1] for x in pershidroph]\n",
        "\n",
        "contact_list = num_dist_pos + num_dist_his + num_dist_lys + num_dist_cys + num_dist_hidrop\n",
        "\n",
        "pml_file = distance_pml(nrl_dic, FILE_NAME)\n",
        "\n",
        "nrl_list = [x.split('_')[0] for x in nrl]\n",
        "import py3Dmol\n",
        "view = py3Dmol.view()\n",
        "try:\n",
        "    view.addModel(open(PDB_FILE,'r').read(),'pdb')\n",
        "except FileNotFoundError:\n",
        "    print('There is no pdb file in the Surface folder... and it should be named query.pdb!')\n",
        "\n",
        "view.setStyle({'model':-1},{'cartoon': {'color':'white'}})\n",
        "view.setBackgroundColor('black')\n",
        "view.setStyle({'resi': num_cluster_pos}, {\"sphere\": {'color': 'blue'}})\n",
        "view.setStyle({'resi': num_cluster_neg}, {\"sphere\": {'color': 'red'}})\n",
        "view.setStyle({'resi': num_cluster_his}, {\"sphere\": {'color': 'cyan'}})\n",
        "view.setStyle({'resi': num_cluster_lys}, {\"sphere\": {'color': 'lightblue'}})\n",
        "view.setStyle({'resi': num_cluster_cys}, {\"sphere\": {'color': 'yellow'}})\n",
        "view.setStyle({'resi': num_dist_hidrop}, {\"sphere\": {'color': 'white'}})\n",
        "view.setStyle({'resi': contact_list}, {\"sphere\": {'color': 'magenta'}})\n",
        "view.setStyle({'resi': nrl_list}, {\"sphere\": {'color': 'gray'}})\n",
        "\n",
        "print('The dangerous contacts are marked in magenta and the selected residue in gray!')\n",
        "view.zoomTo()\n",
        "view.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6-2nmKglBj7M"
      },
      "outputs": [],
      "source": [
        "#@title Download your results:\n",
        "#@markdown Just indicate your project name with the full path (Ex. TEST) to donwload all results in a zip file.\n",
        "PROJECT = \"test\" #@param {type:\"string\"}\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "PROJECT_NAME = PROJECT + '.tar.gz'\n",
        "\n",
        "!tar -zcf $PROJECT_NAME $PROJECT\n",
        "\n",
        "from google.colab import files\n",
        "files.download(PROJECT_NAME)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlbGrMoitX9FVtSzV9qbN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}